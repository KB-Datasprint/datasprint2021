{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load and clean data with Python and pandas\n",
    "\n",
    "This notebook shows you how to load parliarmentary text data into a pandas DataFrame, clean the data and extract text from a single party into a text file.\n",
    "\n",
    "First, we import the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "We define the path to a data file and load the data using pandas' `read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file = '/work/Common-files/Data/Datasæt3/20101.csv' # Path to data file\n",
    "\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our data are loaded into a pandas DataFrame. We can inspect the shape of the DataFrame to check that the data are loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `columns` to list the columns of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head()` command returns the first 5 rows of the DataFrame. Here we get a peak of the structure of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `speaker_name` column includes the name of the current speaker. `group_name` shows the party affiliation in abbreviated form. `role` indicates any specific role at the time of speech. `start_time` and `end_time` indicates the date and time of when the speech segment starts and stops, respectively. Finally, the `text` column contains a transcription of the speech segment; i.e. the words spoken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "Depending on the initial state of the data, we can process it and clean it in different ways. This will make the data more managable in our future analyses. The data from ODA (2009-) is of very good quality while older, OCR-scanned data might need a bit more work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the data\n",
    "When cleaning text data, we can use regular expression as a sophisticated Find & Replace tool. Regular expressions are included with pandas. If needed outside pandas, we can use Python's built-in `re` library.\n",
    "\n",
    "Regular expressions are notoriously confusing and will often cause more problems than they solve. However, when used carefully, they are a very powerful tool.\n",
    "\n",
    "Below we access the data in the `text` column of our DataFrame. We use the pandas string method `replace()`. The first argument is what we want to replace (in this case a regular expression). The second argument is what we want to replace it with (in this case an empty string because we just want to remove characters).\n",
    "\n",
    "Briefly, this regular expression removes all punctuation and symbols caused by faulty OCR. The expression `[^\\w\\d\\s]` finds all letters (`\\w`), digits (`\\d`) and spaces (`\\s`). The square brackets indicate that any of the elements within will be replaced. Finally, the caret (`^`) negates the entire expression meaning that characters that are not a letter, a digit or a space will be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].str.replace('[^\\w\\d\\s]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `\\w` includes all letters from A-Z, both upper and lower case. If we want to keep other letters specific to our domain, we can add them to the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].str.replace('[^\\w\\d\\sÆæØøÅåÄäÖöÜü]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the analysis, we might choose to keep some basic punctuation such as commas and full stops, in order to keep some readability for humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].str.replace('[^\\w\\d\\sÆæØøÅåÄäÖöÜü.,§]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are happy with our expression, we save the filtered data by assigning it to the `text` column; or a new column if we want to keep the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('[^\\w\\d\\sÆæØøÅåÄäÖöÜü.,§]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did I mention that regular expression can be confusing? If you want to learn more about regular expressions have a look at the [documentation](https://docs.python.org/3/howto/regex.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case conversion\n",
    "Another way to make the data more managable is to convert all letters to lower case. This is useful if we want to search for specific terms and when we start counting occurences of terms because we wont have to worry about how the words appear in the original text.\n",
    "\n",
    "To convert the text data in the `text` column to lower case we simply use the string method `lower()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single party text extraction\n",
    "Once we have cleaned our text, we might want to select parts of the data to work with. We use the following method to extract all text of a specific party from the DataFrame into one string of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the `unique()` method to get a list of available party IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select a party and use the string method `join()` to combine the text fields of all rows where the title field matches the selected party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party = 'RV'\n",
    "\n",
    "full_text = ' '.join(df[df['group_name'] == party]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have one huge text string `full_text` with all the text from a specific party, which is a great point of departure for further analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can save the full text string to a text file for easier future access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_destination = f'{party}_fulltext.txt'\n",
    "\n",
    "with open(file_destination, 'w', encoding='utf-8') as f:\n",
    "    f.write(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook briefly demonstrated how we can handle and process our data with Python and pandas. These basic tools are useful starting points when we begin analysing our data and you are encouraged to revisit them later on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
